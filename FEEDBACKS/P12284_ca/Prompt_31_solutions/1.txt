Here's a feedback text for the provided Python program:

---

### Feedback: Paraules més freqüents

**Problem Summary:**
The problem requires reading a sequence of `n` words and identifying the `k` most frequent ones. The output should list these `k` words in descending order of frequency. In case of a tie in frequency, words should be sorted alphabetically (lexicographically) in ascending order. The program must handle multiple test cases and print a separator line of ten hyphens after each case.

**Solution Approach:**
The program implements a highly effective and Pythonic approach to solve this problem. For each test case:
1.  It initializes an empty dictionary (`freq`) to store word frequencies.
2.  It reads `n` words one by one, incrementing their count in the `freq` dictionary. This efficiently builds a frequency map for all unique words.
3.  Once all words are processed, it sorts the keys (words) of the `freq` dictionary. The sorting is done using a custom `lambda` function as a key, which prioritizes words with higher frequencies (by negating the frequency value for descending order) and then uses alphabetical order for tie-breaking.
4.  Finally, it iterates through the top `k` sorted words and prints them, followed by the required separator.

**Analysis of the Code:**

**Strengths:**

*   **Correctness:** The logic correctly handles both frequency-based sorting and the lexicographical tie-breaking rule using a single, elegant `lambda` function in the `sorted()` call: `key=lambda x: (-freq[x], x)`. This perfectly matches the problem's requirements.
*   **Efficiency:**
    *   Using a dictionary (`dict[str, int]`) for frequency counting provides an average time complexity of O(N) for reading and counting `N` words, which is very efficient.
    *   Sorting the unique words (let's say `U` unique words) takes O(U log U) time. Given that `U <= N`, this is a highly optimal sorting strategy compared to iterative search approaches.
    *   The overall solution is very performant for the given constraints.
*   **Readability:** The code is well-structured with clear function names (`avalua`, `printea`, `main`) and the use of type hints, which enhances its readability and maintainability.
*   **Pythonic Style:** The use of dictionaries for frequency maps and `lambda` functions for custom sorting keys are idiomatic and highly Pythonic practices.
*   **Multi-case Handling:** The `for n in tokens(int):` loop correctly processes multiple test cases, resetting the frequency dictionary for each new case.

**Weaknesses (Minor points for consideration):**

*   **Wildcard Import:** `from yogi import *` is generally discouraged in larger projects as it can lead to name conflicts. While common in competitive programming contexts, specifying individual imports (`from yogi import tokens, read`) is a good practice.
*   **`printea` loop structure:** The `if k > 0: ... k -= 1` pattern for printing the first `k` items can be slightly more concise using list slicing after sorting, e.g., `for paraula in sorted_words[:k]: print(paraula)`. This makes the intention of printing only the top `k` items more explicit.
*   **`freq` parameter in `avalua`:** The `freq` dictionary is passed as a parameter to `avalua` from `main` even though it's always empty at the point of call. It's then populated within `avalua`. While this works perfectly fine due to Python's mutable dictionary behavior, one could argue for either initializing it inside `avalua` and returning it, or passing it directly to `printea` from `main` after `avalua` has populated it (if `avalua` returned it). This is a minor stylistic choice and doesn't impact correctness or performance.

**Suggestions for Improvement:**

1.  **Refine Imports:** Change `from yogi import *` to `from yogi import tokens, read` for better clarity and to adhere to best practices.
2.  **Concise Printing in `printea`:** Modify the `printea` function to use list slicing for more concise code:
    ```python
    def printea(freq: dict[str, int], k: int):
        sorted_words = sorted(freq.keys(), key=lambda x: (-freq[x], x))
        for paraula in sorted_words[:k]:
            print(paraula)
    ```
3.  **Alternative (for consideration, not strictly an improvement for this specific code):** For larger problems or when `collections` module is allowed, `collections.Counter` could further simplify the frequency counting step:
    ```python
    from collections import Counter
    # ... inside avalua ...
    words_list = [read(str) for _ in range(n)]
    freq = Counter(words_list)
    # ... then call printea(freq, k) ...
    ```
    However, for individual word reads from `yogi`, your current dictionary approach is perfectly suitable and efficient.

---
The solution is well-designed, efficient, and correctly implements all problem requirements. The suggestions are mostly stylistic refinements rather than critical fixes. Well done!